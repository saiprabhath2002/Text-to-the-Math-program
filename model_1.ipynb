{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1772c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:49.779706Z",
     "iopub.status.busy": "2024-04-03T14:11:49.778927Z",
     "iopub.status.idle": "2024-04-03T14:11:55.478061Z",
     "shell.execute_reply": "2024-04-03T14:11:55.477270Z"
    },
    "papermill": {
     "duration": 5.71097,
     "end_time": "2024-04-03T14:11:55.480393",
     "exception": false,
     "start_time": "2024-04-03T14:11:49.769423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchtext.vocab as vocab\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from ordered_set import OrderedSet\n",
    "# glove_dim=100\n",
    "# glove = vocab.GloVe(name='6B', dim=glove_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2681db09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:55.498098Z",
     "iopub.status.busy": "2024-04-03T14:11:55.497364Z",
     "iopub.status.idle": "2024-04-03T14:11:55.559286Z",
     "shell.execute_reply": "2024-04-03T14:11:55.558452Z"
    },
    "papermill": {
     "duration": 0.072501,
     "end_time": "2024-04-03T14:11:55.561121",
     "exception": false,
     "start_time": "2024-04-03T14:11:55.488620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcc0299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:55.577945Z",
     "iopub.status.busy": "2024-04-03T14:11:55.577647Z",
     "iopub.status.idle": "2024-04-03T14:11:55.582860Z",
     "shell.execute_reply": "2024-04-03T14:11:55.582020Z"
    },
    "papermill": {
     "duration": 0.015882,
     "end_time": "2024-04-03T14:11:55.584792",
     "exception": false,
     "start_time": "2024-04-03T14:11:55.568910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_tags=[\"<sos>\",\"<eos>\",\"<unk>\",\"<pad>\"]\n",
    "symbols = [\"(\", \")\", \",\",\"|\",\"const_\"]\n",
    "symbols.extend(range(10))\n",
    "pos_special_tokens_prob=[0,0,0,0]\n",
    "pos_special_tokens_sol=[0,0,0,0]\n",
    "embed_dim=100\n",
    "beam_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119c2143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:55.601166Z",
     "iopub.status.busy": "2024-04-03T14:11:55.600907Z",
     "iopub.status.idle": "2024-04-03T14:11:55.608518Z",
     "shell.execute_reply": "2024-04-03T14:11:55.607735Z"
    },
    "papermill": {
     "duration": 0.017892,
     "end_time": "2024-04-03T14:11:55.610269",
     "exception": false,
     "start_time": "2024-04-03T14:11:55.592377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    \n",
    "    max_len_problem = max([len(sample[0]) for sample in batch])\n",
    "    max_len_solution = max([len(sample[1]) for sample in batch])\n",
    "    \n",
    "    padded_prob = torch.empty((len(batch), max_len_problem), dtype=torch.long)\n",
    "    padded_prob.fill_(pos_special_tokens_prob[3])\n",
    "    padded_sol = torch.empty((len(batch), max_len_solution), dtype=torch.long)\n",
    "    padded_sol.fill_(pos_special_tokens_sol[3])\n",
    "    ans=torch.zeros(len(batch))\n",
    "\n",
    "    for idx in range(len(batch)):\n",
    "        \n",
    "        ans[idx]=batch[idx][2]\n",
    "        padded_prob[idx, :len(batch[idx][0])] = torch.LongTensor(batch[idx][0])\n",
    "        padded_sol[idx, :len(batch[idx][1])] = torch.LongTensor(batch[idx][1])\n",
    "        \n",
    "    return (padded_prob,padded_sol,ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62deefc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:55.627106Z",
     "iopub.status.busy": "2024-04-03T14:11:55.626704Z",
     "iopub.status.idle": "2024-04-03T14:11:55.646150Z",
     "shell.execute_reply": "2024-04-03T14:11:55.645329Z"
    },
    "papermill": {
     "duration": 0.029946,
     "end_time": "2024-04-03T14:11:55.647942",
     "exception": false,
     "start_time": "2024-04-03T14:11:55.617996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class load_data_train(Dataset):\n",
    "    def __init__(self,json_path):\n",
    "        self.path=json_path\n",
    "        self.data=[]\n",
    "        self.loaddata()\n",
    "        self.problem_unique_words,self.sol_unique_words=self.gen_all_unique_words()\n",
    "        self.problem_word2int = {word: i for i, word in enumerate(self.problem_unique_words)}\n",
    "        self.problem_int2word = {i: word for word, i in self.problem_word2int.items()}\n",
    "        self.sol_word2int = {word: i for i, word in enumerate(self.sol_unique_words)}\n",
    "        self.sol_int2word = {i: word for word, i in self.sol_word2int.items()}\n",
    "        self.max_problem_len=self.get_max_len()\n",
    "        self.get_special_pos_prob()\n",
    "        self.get_special_pos_sol()\n",
    "    def get_special_pos_prob(self):\n",
    "        for i,t in enumerate(special_tags):\n",
    "            pos_special_tokens_prob[i]=self.problem_word2int[t]\n",
    "            \n",
    "    def get_special_pos_sol(self):\n",
    "        for i,t in enumerate(special_tags):\n",
    "            pos_special_tokens_sol[i]=self.sol_word2int[t]\n",
    "            \n",
    "    def gen_all_unique_words(self):\n",
    "        u1=OrderedSet(special_tags)\n",
    "        u2=OrderedSet(symbols+special_tags)\n",
    "        for i,(prob,sol,a) in enumerate(self.data):\n",
    "            for word in prob.split():\n",
    "                u1.add(word)\n",
    "            operations = sol.split(\"|\")\n",
    "            l=self.tokanize_sol(i)\n",
    "            for t in l:\n",
    "                u2.add(t)\n",
    "        return u1,u2\n",
    "    \n",
    "    def tokanize_problem(self,i):\n",
    "        return self.data[i][0].split()\n",
    "    \n",
    "    def tokanize_sol(self,i):\n",
    "        l=[]\n",
    "        operations = self.data[i][1].split(\"|\")\n",
    "        for j,operation in enumerate(operations):\n",
    "            if not operation:  \n",
    "                continue\n",
    "            operation_name = operation.split(\"(\")[0]\n",
    "            l.append(operation_name) \n",
    "            l.append(\"(\")\n",
    "            content = operation[operation.find(\"(\")+1:operation.find(\")\")]\n",
    "            tokens = content.split(\",\")\n",
    "            new=[]\n",
    "            for i, token in enumerate(tokens):\n",
    "                new.append(token)\n",
    "                if i < len(tokens) - 1:\n",
    "                    new.append(\",\")\n",
    "            l.extend(new)\n",
    "            l.append(\")\")\n",
    "            if j < len(operations) - 1:\n",
    "                    l.append(\"|\")\n",
    "        return l\n",
    "    \n",
    "    def get_max_len(self):\n",
    "        m=0\n",
    "        for (p,s,a) in self.data:\n",
    "            for p1 in p:\n",
    "                m=max(m,len(p1.split()))\n",
    "        return m\n",
    "\n",
    "    def loaddata(self):\n",
    "        with open(self.path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for i in data:\n",
    "                #list(i[\"Problem\"].split())\n",
    "#                 p=str(i[\"Problem\"]).split()\n",
    "                self.data.append((i[\"Problem\"],i[\"linear_formula\"],i[\"answer\"]))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        problem=[\"<sos>\"]+self.tokanize_problem(i)+[\"<eos>\"]\n",
    "        sol=[\"<sos>\"]+self.tokanize_sol(i)+[\"<eos>\"]\n",
    "        problem = [self.problem_word2int[q] if q in self.problem_word2int else self.problem_word2int[\"<unk>\"] for q in problem]\n",
    "        sol = [self.sol_word2int[q] if q in self.sol_word2int else self.sol_word2int[\"<unk>\"] for q in sol]\n",
    "        return ((problem,sol,self.data[i][2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4798d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:55.665547Z",
     "iopub.status.busy": "2024-04-03T14:11:55.665297Z",
     "iopub.status.idle": "2024-04-03T14:11:55.677578Z",
     "shell.execute_reply": "2024-04-03T14:11:55.676928Z"
    },
    "papermill": {
     "duration": 0.023902,
     "end_time": "2024-04-03T14:11:55.679431",
     "exception": false,
     "start_time": "2024-04-03T14:11:55.655529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class load_data_test(Dataset):\n",
    "    def __init__(self,json_path,train):\n",
    "        self.path=json_path\n",
    "        self.data=[]\n",
    "        self.loaddata()\n",
    "        self.problem_unique_words,self.sol_unique_words=train.problem_unique_words,train.sol_unique_words\n",
    "        self.problem_word2int = train.problem_word2int\n",
    "        self.problem_int2word = train.problem_int2word\n",
    "        self.sol_word2int = train.sol_word2int\n",
    "        self.sol_int2word =train.sol_int2word\n",
    "    \n",
    "    def tokanize_problem(self,i):\n",
    "        return self.data[i][0].split()\n",
    "    \n",
    "    def tokanize_sol(self,i):\n",
    "        l=[]\n",
    "        operations = self.data[i][1].split(\"|\")\n",
    "        for j,operation in enumerate(operations):\n",
    "            if not operation:  \n",
    "                continue\n",
    "            operation_name = operation.split(\"(\")[0]\n",
    "            l.append(operation_name)\n",
    "            l.append(\"(\")\n",
    "            content = operation[operation.find(\"(\")+1:operation.find(\")\")]\n",
    "            tokens = content.split(\",\")\n",
    "            new=[]\n",
    "            for i, token in enumerate(tokens):\n",
    "                new.append(token)\n",
    "                if i < len(tokens) - 1:\n",
    "                    new.append(\",\")\n",
    "            l.extend(new)\n",
    "            l.append(\")\")\n",
    "            if j < len(operations) - 1:\n",
    "                    l.append(\"|\")\n",
    "        return l\n",
    "\n",
    "    def loaddata(self):\n",
    "        with open(self.path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for i in data:\n",
    "                #list(i[\"Problem\"].split())\n",
    "#                 p=str(i[\"Problem\"]).split()\n",
    "                self.data.append((i[\"Problem\"],i[\"linear_formula\"],i[\"answer\"]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        problem=[\"<sos>\"]+self.tokanize_problem(i)+[\"<eos>\"]\n",
    "        sol=[\"<sos>\"]+self.tokanize_sol(i)+[\"<eos>\"]\n",
    "        problem = [self.problem_word2int[q] if q in self.problem_word2int else self.problem_word2int[\"<unk>\"] for q in problem]\n",
    "        sol = [self.sol_word2int[q] if q in self.sol_word2int else self.sol_word2int[\"<unk>\"] for q in sol]\n",
    "        return ((problem,sol,self.data[i][2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d8d9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:55.695880Z",
     "iopub.status.busy": "2024-04-03T14:11:55.695606Z",
     "iopub.status.idle": "2024-04-03T14:11:57.886479Z",
     "shell.execute_reply": "2024-04-03T14:11:57.885589Z"
    },
    "papermill": {
     "duration": 2.201735,
     "end_time": "2024-04-03T14:11:57.888841",
     "exception": false,
     "start_time": "2024-04-03T14:11:55.687106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path=\"/kaggle/input/new-wp/data/train.json\"\n",
    "train_data=load_data_train(train_path)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=False, collate_fn=collate)\n",
    "\n",
    "test_path=\"/kaggle/input/new-wp/data/test.json\"\n",
    "test_data=load_data_test(test_path,train_data)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate)\n",
    "\n",
    "\n",
    "\n",
    "validation_path=\"/kaggle/input/new-wp/data/dev.json\"\n",
    "val_data=load_data_test(validation_path,train_data)\n",
    "validation_loader = DataLoader(val_data, batch_size=64, shuffle=False, collate_fn=collate)\n",
    "validation_loader1 = DataLoader(val_data, batch_size=1, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3251e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:57.906090Z",
     "iopub.status.busy": "2024-04-03T14:11:57.905793Z",
     "iopub.status.idle": "2024-04-03T14:11:57.912387Z",
     "shell.execute_reply": "2024-04-03T14:11:57.911535Z"
    },
    "papermill": {
     "duration": 0.017162,
     "end_time": "2024-04-03T14:11:57.914228",
     "exception": false,
     "start_time": "2024-04-03T14:11:57.897066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19791"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5bf6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:57.931501Z",
     "iopub.status.busy": "2024-04-03T14:11:57.930964Z",
     "iopub.status.idle": "2024-04-03T14:11:57.935766Z",
     "shell.execute_reply": "2024-04-03T14:11:57.934792Z"
    },
    "papermill": {
     "duration": 0.015504,
     "end_time": "2024-04-03T14:11:57.937624",
     "exception": false,
     "start_time": "2024-04-03T14:11:57.922120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[15, 16, 17, 18]\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "print(pos_special_tokens_prob)\n",
    "print(pos_special_tokens_sol)\n",
    "print(train_data.problem_int2word[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5614a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:57.954652Z",
     "iopub.status.busy": "2024-04-03T14:11:57.954382Z",
     "iopub.status.idle": "2024-04-03T14:11:57.961538Z",
     "shell.execute_reply": "2024-04-03T14:11:57.960688Z"
    },
    "papermill": {
     "duration": 0.017677,
     "end_time": "2024-04-03T14:11:57.963379",
     "exception": false,
     "start_time": "2024-04-03T14:11:57.945702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class GloveEmbeddings:\n",
    "    def __init__(self, embedding_dimension, word_to_index):\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.word_to_index = word_to_index\n",
    "        self.vocab_size = len(word_to_index)\n",
    "\n",
    "    def get_embedding_matrix(self):\n",
    "        glove = GloVe(name='6B', dim=self.embedding_dimension)\n",
    "        embeddings = torch.zeros((self.vocab_size, self.embedding_dimension))  # Initialize with zeros\n",
    "\n",
    "        # Initialize special tokens with random embeddings\n",
    "        special_tokens_indexes = pos_special_tokens_prob[:3]\n",
    "        for index in special_tokens_indexes:\n",
    "            embeddings[index] = torch.randn(self.embedding_dimension)\n",
    "\n",
    "        # Populate the embedding matrix with GloVe vectors or fallback for unknown/special tokens\n",
    "        for word, idx in self.word_to_index.items():\n",
    "            if word in glove.stoi:\n",
    "                embeddings[idx] = glove.vectors[glove.stoi[word]]\n",
    "            elif word not in special_tags:\n",
    "                embeddings[idx] = embeddings[pos_special_tokens_prob[2]]\n",
    "\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d72b007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:57.980438Z",
     "iopub.status.busy": "2024-04-03T14:11:57.980186Z",
     "iopub.status.idle": "2024-04-03T14:11:57.983963Z",
     "shell.execute_reply": "2024-04-03T14:11:57.983148Z"
    },
    "papermill": {
     "duration": 0.014601,
     "end_time": "2024-04-03T14:11:57.985956",
     "exception": false,
     "start_time": "2024-04-03T14:11:57.971355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "glove=GloveEmbeddings(200,train_data.problem_word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bb545cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:11:58.004323Z",
     "iopub.status.busy": "2024-04-03T14:11:58.003859Z",
     "iopub.status.idle": "2024-04-03T14:15:40.846818Z",
     "shell.execute_reply": "2024-04-03T14:15:40.845791Z"
    },
    "papermill": {
     "duration": 222.855324,
     "end_time": "2024-04-03T14:15:40.849244",
     "exception": false,
     "start_time": "2024-04-03T14:11:57.993920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:39, 5.41MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:46<00:00, 8525.18it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding=glove.get_embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fff43248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:15:41.165866Z",
     "iopub.status.busy": "2024-04-03T14:15:41.165485Z",
     "iopub.status.idle": "2024-04-03T14:15:41.174477Z",
     "shell.execute_reply": "2024-04-03T14:15:41.173735Z"
    },
    "papermill": {
     "duration": 0.168169,
     "end_time": "2024-04-03T14:15:41.176305",
     "exception": false,
     "start_time": "2024-04-03T14:15:41.008136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "      \n",
    "class lstm_encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_units=512, embed_matrix=None,padding_idx=3):\n",
    "        super(lstm_encoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.embedding = nn.Embedding.from_pretrained(embed_matrix, padding_idx=padding_idx)\n",
    "        self.dropout = nn.Dropout(0.5)  # Reintroduced dropout layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, num_layers=1, batch_first=True, \n",
    "                            dropout=0.5, bidirectional=True)\n",
    "        self.hidden_layer = nn.Linear(hidden_units * 2, hidden_units)  # For the bidirectional concat\n",
    "        self.cell_layer = nn.Linear(hidden_units * 2, hidden_units)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embedded_inputs = self.dropout(self.embedding(inputs))  # Apply dropout after embedding\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded_inputs)\n",
    "        # Concatenate the bidirectional LSTM outputs before applying to the linear layers\n",
    "        hidden = self.hidden_layer(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = self.cell_layer(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        return lstm_out, (hidden, cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64faad7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f102e9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:15:41.490359Z",
     "iopub.status.busy": "2024-04-03T14:15:41.490049Z",
     "iopub.status.idle": "2024-04-03T14:15:41.497488Z",
     "shell.execute_reply": "2024-04-03T14:15:41.496781Z"
    },
    "papermill": {
     "duration": 0.166412,
     "end_time": "2024-04-03T14:15:41.499333",
     "exception": false,
     "start_time": "2024-04-03T14:15:41.332921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class lstm_decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units=512,padding_idx=18):\n",
    "        super(lstm_decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, num_layers=1, batch_first=True, dropout=0.5)\n",
    "        self.output_layer = nn.Linear(hidden_units, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, initial_state):\n",
    "        # Apply dropout after embedding\n",
    "        embedded_inputs = self.dropout(self.embedding(inputs)).unsqueeze(1)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded_inputs, initial_state)\n",
    "        output = self.output_layer(lstm_out.squeeze(1))\n",
    "        return output, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ff764c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:15:41.816971Z",
     "iopub.status.busy": "2024-04-03T14:15:41.816196Z",
     "iopub.status.idle": "2024-04-03T14:15:41.825620Z",
     "shell.execute_reply": "2024-04-03T14:15:41.824787Z"
    },
    "papermill": {
     "duration": 0.170471,
     "end_time": "2024-04-03T14:15:41.827497",
     "exception": false,
     "start_time": "2024-04-03T14:15:41.657026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,embedding=None,embedding_dim=100,max_len_pred=200):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = lstm_encoder(embedding_dim=embedding_dim, embed_matrix=embedding)\n",
    "        self.decoder = lstm_decoder(vocab_size=max_len_pred,embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, source_seq, target_seq, tf=0.9):\n",
    "        src_batch_size = source_seq.size(0)\n",
    "        tgt_seq_len = target_seq.size(1)\n",
    "        \n",
    "        encoder_states, (encoder_hidden, encoder_cell) = self.encoder(source_seq)\n",
    "\n",
    "        decoder_vocab_size = self.decoder.vocab_size\n",
    "        decoder_outputs = torch.zeros(src_batch_size, tgt_seq_len, decoder_vocab_size)\n",
    "        predicted_sequence = torch.zeros(src_batch_size, tgt_seq_len)\n",
    "\n",
    "        decoder_input_token = target_seq[:, 0]  # Initial decoder input\n",
    "        predicted_sequence[:, 0] = decoder_input_token\n",
    "        \n",
    "        for step in range(1, tgt_seq_len):\n",
    "            decoder_output, (encoder_hidden, encoder_cell) = self.decoder(decoder_input_token, (encoder_hidden, encoder_cell))\n",
    "            decoder_output = decoder_output.squeeze(1)\n",
    "            decoder_outputs[:, step, :] = decoder_output\n",
    "            use_teacher_forcing = np.random.random() < tf\n",
    "            decoder_input_token = target_seq[:, step] if use_teacher_forcing else decoder_output.argmax(dim=1)\n",
    "            predicted_sequence[:, step] = decoder_output.argmax(dim=1)\n",
    "\n",
    "        return decoder_outputs, predicted_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1e8871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:15:42.142901Z",
     "iopub.status.busy": "2024-04-03T14:15:42.142186Z",
     "iopub.status.idle": "2024-04-03T14:15:42.470291Z",
     "shell.execute_reply": "2024-04-03T14:15:42.469453Z"
    },
    "papermill": {
     "duration": 0.488391,
     "end_time": "2024-04-03T14:15:42.472508",
     "exception": false,
     "start_time": "2024-04-03T14:15:41.984117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model=Seq2Seq(embedding=embedding,embedding_dim=200,max_len_pred=len(train_data.sol_unique_words)).to(device)\n",
    "def train(epochs):\n",
    "    st=time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_l=[]\n",
    "    val_l=[]\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"=======================epoch {epoch}================================\")\n",
    "        model.train()\n",
    "        l=[]\n",
    "        for j,data1 in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x=data1[0].to(device)\n",
    "            y=data1[1].to(device)\n",
    "            o,w=model(x,y,tf=0.6)\n",
    "            o = o.reshape(-1, o.shape[2]).to(device)\n",
    "            y_orig = y.reshape(-1).to(device)\n",
    "            loss = criterion(o, y_orig)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l.append(loss.item())\n",
    "        train_l.append(np.mean(l))\n",
    "        model.eval()\n",
    "        l=[]\n",
    "        for j,data1 in enumerate(validation_loader):\n",
    "            x=data1[0].to(device)\n",
    "            y=data1[1].to(device)\n",
    "            o,w=model(x,y,tf=0)\n",
    "            o = o.reshape(-1, o.shape[2]).to(device)\n",
    "            y_orig = y.reshape(-1).to(device)\n",
    "            loss = criterion(o, y_orig)\n",
    "            l.append(loss.item())\n",
    "        val_l.append(np.mean(l))\n",
    "        print(f\"epoch : {epoch} train_loss : {train_l[-1]} val_loss: {val_l[-1]} time taken : {(time.time()-st)/60}  \")\n",
    "        print(\"model saved!!\")\n",
    "        torch.save(model, 'modelA.pth')\n",
    "    return train_l,val_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89cacac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:15:42.790047Z",
     "iopub.status.busy": "2024-04-03T14:15:42.789361Z",
     "iopub.status.idle": "2024-04-03T14:57:58.417336Z",
     "shell.execute_reply": "2024-04-03T14:57:58.416297Z"
    },
    "papermill": {
     "duration": 2535.950639,
     "end_time": "2024-04-03T14:57:58.580300",
     "exception": false,
     "start_time": "2024-04-03T14:15:42.629661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================epoch 0================================\n",
      "epoch : 0 train_loss : 0.6141041409584784 val_loss: 2.946491840037894 time taken : 0.8912498315175374  \n",
      "model saved!!\n",
      "=======================epoch 1================================\n",
      "epoch : 1 train_loss : 0.43166935443878174 val_loss: 1.5370731594714713 time taken : 1.7355701684951783  \n",
      "model saved!!\n",
      "=======================epoch 2================================\n",
      "epoch : 2 train_loss : 0.40644503336760307 val_loss: 1.4334168637052496 time taken : 2.5784053643544516  \n",
      "model saved!!\n",
      "=======================epoch 3================================\n",
      "epoch : 3 train_loss : 0.38998422795726406 val_loss: 1.8138292710831825 time taken : 3.4241531014442446  \n",
      "model saved!!\n",
      "=======================epoch 4================================\n",
      "epoch : 4 train_loss : 0.38092816361496523 val_loss: 1.518678014582776 time taken : 4.269885158538818  \n",
      "model saved!!\n",
      "=======================epoch 5================================\n",
      "epoch : 5 train_loss : 0.37034411391904276 val_loss: 1.4124448958863602 time taken : 5.11061776081721  \n",
      "model saved!!\n",
      "=======================epoch 6================================\n",
      "epoch : 6 train_loss : 0.36296743572719636 val_loss: 1.3731888012683138 time taken : 5.946636180082957  \n",
      "model saved!!\n",
      "=======================epoch 7================================\n",
      "epoch : 7 train_loss : 0.3521934397758976 val_loss: 1.264497404402875 time taken : 6.789942701657613  \n",
      "model saved!!\n",
      "=======================epoch 8================================\n",
      "epoch : 8 train_loss : 0.34189711172253856 val_loss: 1.3049557209014893 time taken : 7.635125390688578  \n",
      "model saved!!\n",
      "=======================epoch 9================================\n",
      "epoch : 9 train_loss : 0.3336571567241223 val_loss: 1.2771261790965467 time taken : 8.481835544109344  \n",
      "model saved!!\n",
      "=======================epoch 10================================\n",
      "epoch : 10 train_loss : 0.3233754297177638 val_loss: 1.1873931009718712 time taken : 9.321570241451264  \n",
      "model saved!!\n",
      "=======================epoch 11================================\n",
      "epoch : 11 train_loss : 0.3095214275823486 val_loss: 1.1577483846786174 time taken : 10.169722378253937  \n",
      "model saved!!\n",
      "=======================epoch 12================================\n",
      "epoch : 12 train_loss : 0.29970933946390305 val_loss: 1.1065142649285338 time taken : 11.006408143043519  \n",
      "model saved!!\n",
      "=======================epoch 13================================\n",
      "epoch : 13 train_loss : 0.2908179523243058 val_loss: 1.0721556531622054 time taken : 11.845551252365112  \n",
      "model saved!!\n",
      "=======================epoch 14================================\n",
      "epoch : 14 train_loss : 0.2819405206749516 val_loss: 1.0261348485946655 time taken : 12.69142496585846  \n",
      "model saved!!\n",
      "=======================epoch 15================================\n",
      "epoch : 15 train_loss : 0.2684215918183327 val_loss: 0.9728619862110057 time taken : 13.535391040643056  \n",
      "model saved!!\n",
      "=======================epoch 16================================\n",
      "epoch : 16 train_loss : 0.25943647010191795 val_loss: 0.9987582196580603 time taken : 14.379705186684927  \n",
      "model saved!!\n",
      "=======================epoch 17================================\n",
      "epoch : 17 train_loss : 0.250096565004318 val_loss: 0.9355517473626644 time taken : 15.222373457749685  \n",
      "model saved!!\n",
      "=======================epoch 18================================\n",
      "epoch : 18 train_loss : 0.23948337801041142 val_loss: 0.9024624520159782 time taken : 16.070905431111655  \n",
      "model saved!!\n",
      "=======================epoch 19================================\n",
      "epoch : 19 train_loss : 0.23246913090828927 val_loss: 0.9306749612727063 time taken : 16.91740652322769  \n",
      "model saved!!\n",
      "=======================epoch 20================================\n",
      "epoch : 20 train_loss : 0.22517866578794296 val_loss: 0.8428756658067095 time taken : 17.76314537525177  \n",
      "model saved!!\n",
      "=======================epoch 21================================\n",
      "epoch : 21 train_loss : 0.21781540944451286 val_loss: 0.875358632270326 time taken : 18.606799785296122  \n",
      "model saved!!\n",
      "=======================epoch 22================================\n",
      "epoch : 22 train_loss : 0.2107232155098069 val_loss: 0.8464170301214178 time taken : 19.450319560368857  \n",
      "model saved!!\n",
      "=======================epoch 23================================\n",
      "epoch : 23 train_loss : 0.20370335312139604 val_loss: 0.8203480592433442 time taken : 20.29417488972346  \n",
      "model saved!!\n",
      "=======================epoch 24================================\n",
      "epoch : 24 train_loss : 0.19703440050924978 val_loss: 0.8284434866397938 time taken : 21.136468601226806  \n",
      "model saved!!\n",
      "=======================epoch 25================================\n",
      "epoch : 25 train_loss : 0.19177672455628073 val_loss: 0.8249332758974521 time taken : 21.974117763837178  \n",
      "model saved!!\n",
      "=======================epoch 26================================\n",
      "epoch : 26 train_loss : 0.18586556451214897 val_loss: 0.7540525870120272 time taken : 22.819011704126993  \n",
      "model saved!!\n",
      "=======================epoch 27================================\n",
      "epoch : 27 train_loss : 0.18051919094737498 val_loss: 0.7703531492263713 time taken : 23.664648139476775  \n",
      "model saved!!\n",
      "=======================epoch 28================================\n",
      "epoch : 28 train_loss : 0.17676577981441252 val_loss: 0.7348651327985398 time taken : 24.50571463108063  \n",
      "model saved!!\n",
      "=======================epoch 29================================\n",
      "epoch : 29 train_loss : 0.17205862180600243 val_loss: 0.7510489796070342 time taken : 25.349535803000133  \n",
      "model saved!!\n",
      "=======================epoch 30================================\n",
      "epoch : 30 train_loss : 0.1685245095001113 val_loss: 0.7092847399255062 time taken : 26.194384320576987  \n",
      "model saved!!\n",
      "=======================epoch 31================================\n",
      "epoch : 31 train_loss : 0.16450645894773544 val_loss: 0.7290509603124984 time taken : 27.038121736049654  \n",
      "model saved!!\n",
      "=======================epoch 32================================\n",
      "epoch : 32 train_loss : 0.15991110691139776 val_loss: 0.7194186601232975 time taken : 27.883764266967773  \n",
      "model saved!!\n",
      "=======================epoch 33================================\n",
      "epoch : 33 train_loss : 0.15755201807666208 val_loss: 0.7180894473765759 time taken : 28.72985794941584  \n",
      "model saved!!\n",
      "=======================epoch 34================================\n",
      "epoch : 34 train_loss : 0.15445911264227283 val_loss: 0.6684542323680635 time taken : 29.570967400074004  \n",
      "model saved!!\n",
      "=======================epoch 35================================\n",
      "epoch : 35 train_loss : 0.15183617940112468 val_loss: 0.7036201338818733 time taken : 30.419924906889598  \n",
      "model saved!!\n",
      "=======================epoch 36================================\n",
      "epoch : 36 train_loss : 0.1495350992487323 val_loss: 0.7284517186753293 time taken : 31.285119088490806  \n",
      "model saved!!\n",
      "=======================epoch 37================================\n",
      "epoch : 37 train_loss : 0.14591054867111866 val_loss: 0.6832931124149485 time taken : 32.140923869609836  \n",
      "model saved!!\n",
      "=======================epoch 38================================\n",
      "epoch : 38 train_loss : 0.1449509697215211 val_loss: 0.6929945974273884 time taken : 32.98919179836909  \n",
      "model saved!!\n",
      "=======================epoch 39================================\n",
      "epoch : 39 train_loss : 0.1410437079807443 val_loss: 0.7038890373833636 time taken : 33.83195434411367  \n",
      "model saved!!\n",
      "=======================epoch 40================================\n",
      "epoch : 40 train_loss : 0.13939628212923003 val_loss: 0.6939638269708511 time taken : 34.66956710020701  \n",
      "model saved!!\n",
      "=======================epoch 41================================\n",
      "epoch : 41 train_loss : 0.13805408804647384 val_loss: 0.6716914253031954 time taken : 35.507329948743184  \n",
      "model saved!!\n",
      "=======================epoch 42================================\n",
      "epoch : 42 train_loss : 0.1357682762487281 val_loss: 0.7465076091441702 time taken : 36.350391097863515  \n",
      "model saved!!\n",
      "=======================epoch 43================================\n",
      "epoch : 43 train_loss : 0.13382632550933668 val_loss: 0.6957149448546958 time taken : 37.19626200199127  \n",
      "model saved!!\n",
      "=======================epoch 44================================\n",
      "epoch : 44 train_loss : 0.1343094941228628 val_loss: 0.6776682943739789 time taken : 38.033155651887256  \n",
      "model saved!!\n",
      "=======================epoch 45================================\n",
      "epoch : 45 train_loss : 0.1321287493191419 val_loss: 0.6974600933967753 time taken : 38.8768536845843  \n",
      "model saved!!\n",
      "=======================epoch 46================================\n",
      "epoch : 46 train_loss : 0.1289379816382162 val_loss: 0.6962121021240315 time taken : 39.72256069183349  \n",
      "model saved!!\n",
      "=======================epoch 47================================\n",
      "epoch : 47 train_loss : 0.12893248016555464 val_loss: 0.6863243862035426 time taken : 40.571841669082644  \n",
      "model saved!!\n",
      "=======================epoch 48================================\n",
      "epoch : 48 train_loss : 0.1266811830862876 val_loss: 0.6566986581112476 time taken : 41.42092976172765  \n",
      "model saved!!\n",
      "=======================epoch 49================================\n",
      "epoch : 49 train_loss : 0.12598826650890613 val_loss: 0.6915707845003047 time taken : 42.259334750970204  \n",
      "model saved!!\n",
      "training completed\n"
     ]
    }
   ],
   "source": [
    "train_l,val_l=train(50)\n",
    "print(\"training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67f30711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:57:58.948439Z",
     "iopub.status.busy": "2024-04-03T14:57:58.947892Z",
     "iopub.status.idle": "2024-04-03T14:57:58.994610Z",
     "shell.execute_reply": "2024-04-03T14:57:58.993872Z"
    },
    "papermill": {
     "duration": 0.211194,
     "end_time": "2024-04-03T14:57:58.996808",
     "exception": false,
     "start_time": "2024-04-03T14:57:58.785614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'modelA_final_50_epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa2d5a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:57:59.322081Z",
     "iopub.status.busy": "2024-04-03T14:57:59.321719Z",
     "iopub.status.idle": "2024-04-03T14:57:59.328638Z",
     "shell.execute_reply": "2024-04-03T14:57:59.327802Z"
    },
    "papermill": {
     "duration": 0.171638,
     "end_time": "2024-04-03T14:57:59.330443",
     "exception": false,
     "start_time": "2024-04-03T14:57:59.158805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_csv(model,data,loader):\n",
    "    model.eval()\n",
    "    prediction=[]\n",
    "    for batch in loader:\n",
    "        x=batch[0].to(device)\n",
    "        y=batch[1].to(device)\n",
    "        o,w=model(x,y,tf=0)\n",
    "        prediction.append(w)\n",
    "    predicted_data_strings=[]\n",
    "    for batch in prediction:\n",
    "        for one_data in batch:\n",
    "            one_data=one_data.to(torch.int)\n",
    "            one_data_in_string=\"\"\n",
    "            conv_int_word=[]\n",
    "            for pos,value in enumerate(one_data):\n",
    "                conv_int_word.append(data.sol_int2word[value.item()])\n",
    "            predicted_data_strings.append(conv_int_word)\n",
    "    return predicted_data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf4c660c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:57:59.654891Z",
     "iopub.status.busy": "2024-04-03T14:57:59.654544Z",
     "iopub.status.idle": "2024-04-03T14:57:59.660552Z",
     "shell.execute_reply": "2024-04-03T14:57:59.659716Z"
    },
    "papermill": {
     "duration": 0.169995,
     "end_time": "2024-04-03T14:57:59.662394",
     "exception": false,
     "start_time": "2024-04-03T14:57:59.492399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_sol(data2str):\n",
    "    complete_data=[]\n",
    "    for each_data in data2str:\n",
    "        s=\"\"\n",
    "        flag=0\n",
    "        for item in each_data[1:]:\n",
    "            if(item==\"<eos>\" or item==\"<pad>\"):\n",
    "                complete_data.append(s)\n",
    "                flag=1\n",
    "                break\n",
    "            else:\n",
    "                s+=str(item)\n",
    "        if(flag==0):\n",
    "            complete_data.append(s)\n",
    "    return complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca977d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:57:59.984498Z",
     "iopub.status.busy": "2024-04-03T14:57:59.984191Z",
     "iopub.status.idle": "2024-04-03T14:57:59.990111Z",
     "shell.execute_reply": "2024-04-03T14:57:59.989265Z"
    },
    "papermill": {
     "duration": 0.168878,
     "end_time": "2024-04-03T14:57:59.992121",
     "exception": false,
     "start_time": "2024-04-03T14:57:59.823243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sol(int2data,name,data_name):\n",
    "    json_data=[]\n",
    "    for k,s in zip(data_name.data,int2data):\n",
    "        d={\n",
    "            \"Problem\":k[0],\n",
    "            \"answer\":k[2],\n",
    "            \"predicted\":s,\n",
    "            \"linear_formula\":k[1]\n",
    "        }\n",
    "        json_data.append(d)\n",
    "    with open(str(name)+\".json\", 'w') as json_file:\n",
    "        json.dump(json_data, json_file,indent=4)\n",
    "    print(\"prediction json generated!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad6cba3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:00.315569Z",
     "iopub.status.busy": "2024-04-03T14:58:00.314703Z",
     "iopub.status.idle": "2024-04-03T14:58:25.024383Z",
     "shell.execute_reply": "2024-04-03T14:58:25.023509Z"
    },
    "papermill": {
     "duration": 24.87431,
     "end_time": "2024-04-03T14:58:25.026779",
     "exception": false,
     "start_time": "2024-04-03T14:58:00.152469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2string=generate_csv(model,train_data,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f37ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:25.353284Z",
     "iopub.status.busy": "2024-04-03T14:58:25.352934Z",
     "iopub.status.idle": "2024-04-03T14:58:25.358631Z",
     "shell.execute_reply": "2024-04-03T14:58:25.357790Z"
    },
    "papermill": {
     "duration": 0.170115,
     "end_time": "2024-04-03T14:58:25.360687",
     "exception": false,
     "start_time": "2024-04-03T14:58:25.190572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19791"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b4a3db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:25.685246Z",
     "iopub.status.busy": "2024-04-03T14:58:25.684903Z",
     "iopub.status.idle": "2024-04-03T14:58:25.880637Z",
     "shell.execute_reply": "2024-04-03T14:58:25.879877Z"
    },
    "papermill": {
     "duration": 0.360373,
     "end_time": "2024-04-03T14:58:25.882575",
     "exception": false,
     "start_time": "2024-04-03T14:58:25.522202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "good=extract_sol(data2string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ffbd85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:26.207251Z",
     "iopub.status.busy": "2024-04-03T14:58:26.206557Z",
     "iopub.status.idle": "2024-04-03T14:58:26.212449Z",
     "shell.execute_reply": "2024-04-03T14:58:26.211570Z"
    },
    "papermill": {
     "duration": 0.170024,
     "end_time": "2024-04-03T14:58:26.214363",
     "exception": false,
     "start_time": "2024-04-03T14:58:26.044339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19791"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "800247e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:26.538568Z",
     "iopub.status.busy": "2024-04-03T14:58:26.537922Z",
     "iopub.status.idle": "2024-04-03T14:58:26.825223Z",
     "shell.execute_reply": "2024-04-03T14:58:26.824262Z"
    },
    "papermill": {
     "duration": 0.450732,
     "end_time": "2024-04-03T14:58:26.827137",
     "exception": false,
     "start_time": "2024-04-03T14:58:26.376405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction json generated!!\n"
     ]
    }
   ],
   "source": [
    "generate_sol(good,\"on_train_data\",train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "278baccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:27.153357Z",
     "iopub.status.busy": "2024-04-03T14:58:27.152696Z",
     "iopub.status.idle": "2024-04-03T14:58:27.158270Z",
     "shell.execute_reply": "2024-04-03T14:58:27.157349Z"
    },
    "papermill": {
     "duration": 0.16966,
     "end_time": "2024-04-03T14:58:27.160152",
     "exception": false,
     "start_time": "2024-04-03T14:58:26.990492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def gen_csv(l,name):\n",
    "    csv_file = name+\".csv\"\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Loss\"])  # Write header\n",
    "        for loss in l:\n",
    "            writer.writerow([loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "080017b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T14:58:27.484796Z",
     "iopub.status.busy": "2024-04-03T14:58:27.484451Z",
     "iopub.status.idle": "2024-04-03T14:58:27.490221Z",
     "shell.execute_reply": "2024-04-03T14:58:27.489281Z"
    },
    "papermill": {
     "duration": 0.170367,
     "end_time": "2024-04-03T14:58:27.492194",
     "exception": false,
     "start_time": "2024-04-03T14:58:27.321827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv generated..\n"
     ]
    }
   ],
   "source": [
    "gen_csv(train_l,\"train_loss\")\n",
    "gen_csv(val_l,\"val_loss\")\n",
    "print(\"csv generated..\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4724471,
     "sourceId": 8018328,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4725486,
     "sourceId": 8019679,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2802.250098,
   "end_time": "2024-04-03T14:58:29.280835",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-03T14:11:47.030737",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

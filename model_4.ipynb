{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:24.181931Z","iopub.status.busy":"2024-04-04T10:50:24.181448Z","iopub.status.idle":"2024-04-04T10:50:24.188348Z","shell.execute_reply":"2024-04-04T10:50:24.187234Z","shell.execute_reply.started":"2024-04-04T10:50:24.181900Z"},"papermill":{"duration":9.405089,"end_time":"2024-03-31T03:44:53.042657","exception":false,"start_time":"2024-03-31T03:44:43.637568","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import json\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchtext.vocab as vocab\n","from torchtext.vocab import GloVe\n","import torch.nn as nn\n","from tqdm import tqdm\n","import numpy as np\n","import time\n","from transformers import BertModel\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from ordered_set import OrderedSet\n","import random\n","from transformers import BertTokenizer\n","# glove_dim=100\n","# glove = vocab.GloVe(name='6B', dim=glove_dim) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:24.399793Z","iopub.status.busy":"2024-04-04T10:50:24.399138Z","iopub.status.idle":"2024-04-04T10:50:24.404679Z","shell.execute_reply":"2024-04-04T10:50:24.403578Z","shell.execute_reply.started":"2024-04-04T10:50:24.399761Z"},"papermill":{"duration":0.08262,"end_time":"2024-03-31T03:44:53.134889","exception":false,"start_time":"2024-03-31T03:44:53.052269","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:24.608518Z","iopub.status.busy":"2024-04-04T10:50:24.607611Z","iopub.status.idle":"2024-04-04T10:50:24.613832Z","shell.execute_reply":"2024-04-04T10:50:24.612883Z","shell.execute_reply.started":"2024-04-04T10:50:24.608484Z"},"papermill":{"duration":0.018422,"end_time":"2024-03-31T03:44:53.162001","exception":false,"start_time":"2024-03-31T03:44:53.143579","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["special_tags=[\"<sos>\",\"<eos>\",\"<unk>\",\"<pad>\"]\n","symbols = [\"(\", \")\", \",\",\"|\",\"const_\"]\n","symbols.extend(range(10))\n","pos_special_tokens_prob=[0,0,0,0]\n","pos_special_tokens_sol=[0,0,0,0]\n","embed_dim=100\n","beam_size=10"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:24.889154Z","iopub.status.busy":"2024-04-04T10:50:24.888447Z","iopub.status.idle":"2024-04-04T10:50:24.900201Z","shell.execute_reply":"2024-04-04T10:50:24.899077Z","shell.execute_reply.started":"2024-04-04T10:50:24.889120Z"},"papermill":{"duration":0.024948,"end_time":"2024-03-31T03:44:53.197675","exception":false,"start_time":"2024-03-31T03:44:53.172727","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def collate(batch):\n","    \n","    max_len_problem = max([len(sample[0]) for sample in batch])\n","    max_len_solution = max([len(sample[1]) for sample in batch])\n","    \n","    padded_prob = torch.empty((len(batch), max_len_problem), dtype=torch.long)\n","    padded_prob.fill_(0)\n","    padded_sol = torch.empty((len(batch), max_len_solution), dtype=torch.long)\n","    padded_sol.fill_(pos_special_tokens_sol[3])\n","    ans=torch.zeros(len(batch))\n","    prob_attn_mask = torch.zeros((len(batch), max_len_problem), dtype=torch.long)\n","    for idx in range(len(batch)):\n","        prob_len = len(batch[idx][0])\n","        ans[idx]=batch[idx][2]\n","        padded_prob[idx, :len(batch[idx][0])] = torch.LongTensor(batch[idx][0])\n","        padded_sol[idx, :len(batch[idx][1])] = torch.LongTensor(batch[idx][1])\n","        prob_attn_mask[idx, :prob_len] = torch.ones((1, prob_len), dtype=torch.long)\n","    return (padded_prob,padded_sol,prob_attn_mask,ans)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:25.100314Z","iopub.status.busy":"2024-04-04T10:50:25.099584Z","iopub.status.idle":"2024-04-04T10:50:25.124162Z","shell.execute_reply":"2024-04-04T10:50:25.123099Z","shell.execute_reply.started":"2024-04-04T10:50:25.100281Z"},"papermill":{"duration":0.042289,"end_time":"2024-03-31T03:44:53.248768","exception":false,"start_time":"2024-03-31T03:44:53.206479","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class load_data_train(Dataset):\n","    def __init__(self,json_path):\n","        self.path=json_path\n","        self.data=[]\n","        self.loaddata()\n","        self.problem_unique_words,self.sol_unique_words=self.gen_all_unique_words()\n","        self.problem_word2int = {word: i for i, word in enumerate(self.problem_unique_words)}\n","        self.problem_int2word = {i: word for word, i in self.problem_word2int.items()}\n","        self.sol_word2int = {word: i for i, word in enumerate(self.sol_unique_words)}\n","        self.sol_int2word = {i: word for word, i in self.sol_word2int.items()}\n","        self.max_problem_len=self.get_max_len()\n","        self.get_special_pos_prob()\n","        self.get_special_pos_sol()\n","        self.en_tokenizer =  BertTokenizer.from_pretrained(\"bert-base-cased\")\n","    def get_special_pos_prob(self):\n","        for i,t in enumerate(special_tags):\n","            pos_special_tokens_prob[i]=self.problem_word2int[t]\n","            \n","    def get_special_pos_sol(self):\n","        for i,t in enumerate(special_tags):\n","            pos_special_tokens_sol[i]=self.sol_word2int[t]\n","            \n","    def gen_all_unique_words(self):\n","        u1=set(special_tags)\n","        u2=set(symbols+special_tags)\n","        for i,(prob,sol,a) in enumerate(self.data):\n","            for word in prob.split():\n","                u1.add(word)\n","            operations = sol.split(\"|\")\n","            for operation in operations:\n","                if not operation:  \n","                    continue\n","                operation_name = operation.split(\"(\")[0]\n","                u2.add(operation_name) \n","                content = operation[operation.find(\"(\")+1:operation.find(\")\")]\n","                tokens = content.split(\",\")\n","                u2.update(tokens)\n","        return u1,u2\n","    \n","    def tokanize_problem(self,i):\n","#         return self.data[i][0].split()\n","        return self.en_tokenizer.encode(self.data[i][0])\n","    \n","    def tokanize_sol(self,i):\n","        l=[]\n","        operations = self.data[i][1].split(\"|\")\n","        for j,operation in enumerate(operations):\n","            if not operation:  \n","                continue\n","            operation_name = operation.split(\"(\")[0]\n","            l.append(operation_name) \n","            l.append(\"(\")\n","            content = operation[operation.find(\"(\")+1:operation.find(\")\")]\n","            tokens = content.split(\",\")\n","            new=[]\n","            for i, token in enumerate(tokens):\n","                new.append(token)\n","                if i < len(tokens) - 1:\n","                    new.append(\",\")\n","            l.extend(new)\n","            l.append(\")\")\n","            if j < len(operations) - 1:\n","                    l.append(\"|\")\n","        return l\n","    \n","    def get_max_len(self):\n","        m=0\n","        for (p,s,a) in self.data:\n","            for p1 in p:\n","                m=max(m,len(p1.split()))\n","        return m\n","\n","    def loaddata(self):\n","        with open(self.path, 'r') as f:\n","            data = json.load(f)\n","            for i in data:\n","                #list(i[\"Problem\"].split())\n","#                 p=str(i[\"Problem\"]).split()\n","                self.data.append((i[\"Problem\"],i[\"linear_formula\"],i[\"answer\"]))\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, i):\n","        problem=self.tokanize_problem(i)\n","        sol=[\"<sos>\"]+self.tokanize_sol(i)+[\"<eos>\"]\n","#         problem = [self.problem_word2int[q] if q in self.problem_word2int else self.problem_word2int[\"<unk>\"] for q in problem]\n","        sol = [self.sol_word2int[q] if q in self.sol_word2int else self.sol_word2int[\"<unk>\"] for q in sol]\n","        return ((problem,sol,self.data[i][2]))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:25.317731Z","iopub.status.busy":"2024-04-04T10:50:25.316790Z","iopub.status.idle":"2024-04-04T10:50:25.332490Z","shell.execute_reply":"2024-04-04T10:50:25.331460Z","shell.execute_reply.started":"2024-04-04T10:50:25.317677Z"},"papermill":{"duration":0.025809,"end_time":"2024-03-31T03:44:53.284179","exception":false,"start_time":"2024-03-31T03:44:53.258370","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class load_data_test(Dataset):\n","    def __init__(self,json_path,train):\n","        self.path=json_path\n","        self.data=[]\n","        self.loaddata()\n","        self.problem_unique_words,self.sol_unique_words=train.problem_unique_words,train.sol_unique_words\n","        self.problem_word2int = train.problem_word2int\n","        self.problem_int2word = train.problem_int2word\n","        self.sol_word2int = train.sol_word2int\n","        self.sol_int2word =train.sol_int2word\n","        self.en_tokenizer =  BertTokenizer.from_pretrained(\"bert-base-cased\")\n","    def tokanize_problem(self,i):\n","        return self.en_tokenizer.encode(self.data[i][0])\n","    \n","    def tokanize_sol(self,i):\n","        l=[]\n","        operations = self.data[i][1].split(\"|\")\n","        for j,operation in enumerate(operations):\n","            if not operation:  \n","                continue\n","            operation_name = operation.split(\"(\")[0]\n","            l.append(operation_name) \n","            l.append(\"(\")\n","            content = operation[operation.find(\"(\")+1:operation.find(\")\")]\n","            tokens = content.split(\",\")\n","            new=[]\n","            for i, token in enumerate(tokens):\n","                new.append(token)\n","                if i < len(tokens) - 1:\n","                    new.append(\",\")\n","            l.extend(new)\n","            l.append(\")\")\n","            if j < len(operations) - 1:\n","                    l.append(\"|\")\n","        return l\n","\n","    def loaddata(self):\n","        with open(self.path, 'r') as f:\n","            data = json.load(f)\n","            for i in data:\n","                self.data.append((i[\"Problem\"],i[\"linear_formula\"],i[\"answer\"]))\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, i):\n","        problem=self.tokanize_problem(i)\n","        sol=[\"<sos>\"]+self.tokanize_sol(i)+[\"<eos>\"]\n","        sol = [self.sol_word2int[q] if q in self.sol_word2int else self.sol_word2int[\"<unk>\"] for q in sol]\n","        return ((problem,sol,self.data[i][2]))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:25.503382Z","iopub.status.busy":"2024-04-04T10:50:25.502771Z","iopub.status.idle":"2024-04-04T10:50:27.884107Z","shell.execute_reply":"2024-04-04T10:50:27.882814Z","shell.execute_reply.started":"2024-04-04T10:50:25.503354Z"},"papermill":{"duration":1.915405,"end_time":"2024-03-31T03:44:55.208067","exception":false,"start_time":"2024-03-31T03:44:53.292662","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_path=\"/kaggle/input/math-wordproblem/data/train.json\"\n","train_data=load_data_train(train_path)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=False, collate_fn=collate)\n","\n","test_path=\"/kaggle/input/math-wordproblem/data/test.json\"\n","test_data=load_data_test(test_path,train_data)\n","test_loader = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate)\n","\n","\n","\n","validation_path=\"/kaggle/input/math-wordproblem/data/dev.json\"\n","val_data=load_data_test(validation_path,train_data)\n","validation_loader = DataLoader(val_data, batch_size=32, shuffle=False, collate_fn=collate)\n","validation_loader1 = DataLoader(val_data, batch_size=1, shuffle=False, collate_fn=collate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:27.886811Z","iopub.status.busy":"2024-04-04T10:50:27.886270Z","iopub.status.idle":"2024-04-04T10:50:27.897102Z","shell.execute_reply":"2024-04-04T10:50:27.895523Z","shell.execute_reply.started":"2024-04-04T10:50:27.886781Z"},"papermill":{"duration":0.018039,"end_time":"2024-03-31T03:44:55.316687","exception":false,"start_time":"2024-03-31T03:44:55.298648","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","\n","class BERT_Encoder(nn.Module):\n","    def __init__(self, fine_tune_layers=2):\n","        super(BERT_Encoder, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","\n","        # Freeze all the parameters\n","        for param in self.bert.parameters():\n","            param.requires_grad = False\n","\n","        # Unfreeze the top n layers\n","        if fine_tune_layers > 0:\n","            for layer in self.bert.encoder.layer[-fine_tune_layers:]:\n","                for param in layer.parameters():\n","                    param.requires_grad = True\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        return outputs.last_hidden_state"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:30.235980Z","iopub.status.busy":"2024-04-04T10:50:30.235558Z","iopub.status.idle":"2024-04-04T10:50:30.243820Z","shell.execute_reply":"2024-04-04T10:50:30.242850Z","shell.execute_reply.started":"2024-04-04T10:50:30.235949Z"},"papermill":{"duration":0.019769,"end_time":"2024-03-31T03:44:55.345053","exception":false,"start_time":"2024-03-31T03:44:55.325284","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim=768, dec_hid_dim=128):\n","        super(Attention, self).__init__()\n","        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n","\n","    def forward(self, encoder_outputs, hidden):\n","        batch_size = encoder_outputs.shape[0]\n","        src_len = encoder_outputs.shape[1]\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # [batch size, src len, dec_hid_dim]\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2))) \n","        attention = self.v(energy).squeeze(2)\n","        return torch.softmax(attention, dim=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:34.824052Z","iopub.status.busy":"2024-04-04T10:50:34.823622Z","iopub.status.idle":"2024-04-04T10:50:34.834483Z","shell.execute_reply":"2024-04-04T10:50:34.833330Z","shell.execute_reply.started":"2024-04-04T10:50:34.824022Z"},"papermill":{"duration":0.022166,"end_time":"2024-03-31T03:44:55.376115","exception":false,"start_time":"2024-03-31T03:44:55.353949","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class LSTM_Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim=200, enc_hid_dim=768, dec_hid_dim=128, dropout=0.5):\n","        super(LSTM_Decoder, self).__init__()\n","        self.attention = Attention()\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim + enc_hid_dim, dec_hid_dim, batch_first=True)\n","        self.fc_out = nn.Linear(enc_hid_dim + dec_hid_dim + emb_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, cell, encoder_outputs):\n","        embedded = self.dropout(self.embedding(input.unsqueeze(1)))  \n","        attn_weighted = self.attention(encoder_outputs, hidden[0]) \n","        attn_weighted = attn_weighted.unsqueeze(1) \n","        weighted = torch.bmm(attn_weighted, encoder_outputs) \n","        rnn_input = torch.cat((embedded, weighted), dim=2)  \n","        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=2).squeeze(1))\n","        return prediction, hidden, cell\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:35.078626Z","iopub.status.busy":"2024-04-04T10:50:35.078277Z","iopub.status.idle":"2024-04-04T10:50:35.089238Z","shell.execute_reply":"2024-04-04T10:50:35.088047Z","shell.execute_reply.started":"2024-04-04T10:50:35.078601Z"},"papermill":{"duration":0.021798,"end_time":"2024-03-31T03:44:55.406701","exception":false,"start_time":"2024-03-31T03:44:55.384903","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self,max_len_pred=None,device=device):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = BERT_Encoder()\n","        self.decoder = LSTM_Decoder(output_dim=max_len_pred)\n","        self.device = device\n","\n","    def forward(self, src,trg, src_mask,  teacher_forcing_ratio=0.5):\n","        batch_size = src.shape[0]\n","        trg_len = trg.shape[1]\n","        trg_vocab_size = self.decoder.embedding.num_embeddings\n","        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n","        encoder_outputs = self.encoder(src, src_mask)\n","        hidden = torch.zeros(1, batch_size, self.decoder.rnn.hidden_size).to(self.device)\n","        cell = torch.zeros(1, batch_size, self.decoder.rnn.hidden_size).to(self.device)\n","        input = trg[:, 0]\n","\n","        for t in range(1, trg_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n","            outputs[:, t, :] = output\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            top1 = output.argmax(1)\n","            input = trg[:, t] if teacher_force else top1\n","        predicted_tokens = outputs.argmax(2) \n","        return outputs,predicted_tokens\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:35.842836Z","iopub.status.busy":"2024-04-04T10:50:35.842200Z","iopub.status.idle":"2024-04-04T10:50:36.447947Z","shell.execute_reply":"2024-04-04T10:50:36.446885Z","shell.execute_reply.started":"2024-04-04T10:50:35.842805Z"},"papermill":{"duration":3.346086,"end_time":"2024-03-31T03:44:58.917810","exception":false,"start_time":"2024-03-31T03:44:55.571724","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["model=Seq2Seq(max_len_pred=len(train_data.sol_unique_words),device=device)\n","if torch.cuda.device_count() > 1:\n","    model = nn.DataParallel(model)\n","model=model.to(device)\n","def train(epochs):\n","    st=time.time()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    train_l=[]\n","    val_l=[]\n","    for epoch in range(epochs):\n","        print(f\"=======================epoch {epoch}================================\")\n","        model.train()\n","        l=[]\n","        for j,data1 in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            x=data1[0].to(device)\n","            y=data1[1].to(device)\n","            att=data1[2].to(device)\n","            o,w=model(x,y,att,teacher_forcing_ratio=0.6)\n","            o = o.reshape(-1, o.shape[2]).to(device)\n","            y_orig = y.reshape(-1).to(device)\n","            loss = criterion(o, y_orig)\n","            loss.backward()\n","            optimizer.step()\n","            l.append(loss.item())\n","        train_l.append(np.mean(l))\n","        model.eval()\n","        l=[]\n","        for j,data1 in enumerate(validation_loader):\n","            x=data1[0].to(device)\n","            y=data1[1].to(device)\n","            att=data1[2].to(device)\n","            o,w=model(x,y,att,teacher_forcing_ratio=0)\n","            o = o.reshape(-1, o.shape[2]).to(device)\n","            y_orig = y.reshape(-1).to(device)\n","            loss = criterion(o, y_orig)\n","            l.append(loss.item())\n","        val_l.append(np.mean(l))\n","        print(f\"epoch : {epoch} train_loss : {train_l[-1]} val_loss: {val_l[-1]} time taken : {(time.time()-st)/60}  \")\n","#         print(\"model saved!!\")\n","#         torch.save(model, 'modelc_inloop.pth')\n","    return train_l,val_l"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:36.603149Z","iopub.status.busy":"2024-04-04T10:50:36.602342Z","iopub.status.idle":"2024-04-04T10:50:36.607011Z","shell.execute_reply":"2024-04-04T10:50:36.605970Z","shell.execute_reply.started":"2024-04-04T10:50:36.603113Z"},"trusted":true},"outputs":[],"source":["# import gc\n","# gc.collect()\n","\n","# # Clear memory allocated by PyTorch\n","# torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:50:37.245340Z","iopub.status.busy":"2024-04-04T10:50:37.244942Z","iopub.status.idle":"2024-04-04T11:00:26.168567Z","shell.execute_reply":"2024-04-04T11:00:26.167432Z","shell.execute_reply.started":"2024-04-04T10:50:37.245311Z"},"papermill":{"duration":20708.59696,"end_time":"2024-03-31T09:30:07.523851","exception":false,"start_time":"2024-03-31T03:44:58.926891","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["train_l,val_l=train(40)\n","print(\"training completed\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:05:05.455490Z","iopub.status.busy":"2024-04-04T10:05:05.455016Z","iopub.status.idle":"2024-04-04T10:05:06.124404Z","shell.execute_reply":"2024-04-04T10:05:06.123592Z","shell.execute_reply.started":"2024-04-04T10:05:05.455454Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"source":["torch.save(model, 'modelD_final_40_epoch.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:16.812926Z","iopub.status.busy":"2024-04-04T10:43:16.812522Z","iopub.status.idle":"2024-04-04T10:43:16.821064Z","shell.execute_reply":"2024-04-04T10:43:16.820183Z","shell.execute_reply.started":"2024-04-04T10:43:16.812896Z"},"trusted":true},"outputs":[],"source":["import csv\n","def gen_csv(l,name):\n","    csv_file = name+\".csv\"\n","    with open(csv_file, mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([\"Loss\"])  # Write header\n","        for loss in l:\n","            writer.writerow([loss])\n","gen_csv(train_l,\"train_loss_model4\")\n","gen_csv(val_l,\"val_loss_model4\")\n","print(\"csv generated..\")"]},{"cell_type":"markdown","metadata":{},"source":["# Beam"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:29.225250Z","iopub.status.busy":"2024-04-04T10:43:29.224473Z","iopub.status.idle":"2024-04-04T10:43:29.245568Z","shell.execute_reply":"2024-04-04T10:43:29.244647Z","shell.execute_reply.started":"2024-04-04T10:43:29.225216Z"},"trusted":true},"outputs":[],"source":["class BeamSearch3():\n","    def __init__(self, model,single_data,model_type, device,  max_target_len=80, beam_size=beam_size):\n","        self.model = model\n","        self.device = device\n","        self.start_token = pos_special_tokens_sol[0]\n","        self.en_ht = None\n","        self.en_ct = None\n","        self.encoder_out=None\n","        self.decoder_input_token=None\n","        self.max_target_len = max_target_len\n","        self.beam_size = beam_size\n","        self.single_data=single_data\n","        self.get_encoder_outputs(model_type)\n","        self.model_type=model_type\n","        self.beam = [([self.start_token], (self.en_ht, self.en_ct), 0)]\n","\n","\n","    def get_encoder_outputs(self,model_type):\n","        if(model_type==1 or model_type==2):\n","            x=self.single_data[0].to(device)\n","            self.encoder_out, (self.en_ht, self.en_ct) = self.model.lstm_encoder(x)\n","\n","        elif(model_type==3 or model_type==4):\n","            src=self.single_data[0].to(device)\n","            src_mask=self.single_data[2].to(device)\n","            batch_size = src.shape[0]\n","            self.encoder_out = self.model.module.encoder(src, src_mask)\n","            self.en_ht = torch.zeros(1, batch_size, self.model.module.decoder.rnn.hidden_size).to(self.device)\n","            self.en_ct = torch.zeros(1, batch_size, self.model.module.decoder.rnn.hidden_size).to(self.device)\n","            \n","\n","    def search(self):\n","        for _ in range(self.max_target_len - 1):\n","            self._expand_beam(self.model_type)\n","            self.beam.sort(key=lambda x: x[2])\n","            self.beam = self.beam[:self.beam_size]\n","\n","        best_candidate = self.beam[0][0]\n","        decoded_words = self._construct_output(best_candidate)\n","        return decoded_words\n","\n","    def _expand_beam(self,model_type):\n","        new_beam = []\n","        for sequence, (ht, ct), score in self.beam:\n","            prev_token = torch.LongTensor([sequence[-1]]).to(self.device)\n","\n","            if(model_type==1):\n","                decoder_out, (ht, ct) = self.model.decoder(prev_token, (ht, ct))\n","            elif(model_type==2):\n","                decoder_out, (ht, ct) = self.model.lstm_decoder(prev_token, (ht, ct),self.encoder_out)\n","            elif(model_type==3 or model_type==4):\n","                decoder_out, ht, ct= self.model.module.decoder(prev_token, ht, ct,self.encoder_out)\n","\n","            decoder_out = decoder_out.squeeze(1)\n","            top_vals, top_inds = decoder_out.topk(self.beam_size, dim=1)\n","\n","            self._add_candidates(new_beam, sequence, ht, ct, score, top_vals, top_inds)\n","\n","        self.beam = new_beam\n","\n","    def _add_candidates(self, new_beam, sequence, ht, ct, score, top_vals, top_inds):\n","        for j in range(self.beam_size):\n","            new_word_idx = top_inds[0][j]\n","            new_seq = sequence + [new_word_idx.item()]\n","            new_word_prob = torch.log(top_vals[0][j])\n","            updated_score = score - new_word_prob\n","            new_candidate = (new_seq, (ht, ct), updated_score)\n","            new_beam.append(new_candidate)\n","\n","    def _construct_output(self, best_candidate):\n","        decoded_words = torch.zeros(1, self.max_target_len)\n","        for t, idx in enumerate(best_candidate):\n","            decoded_words[:, t] = torch.LongTensor([idx])\n","        return decoded_words"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:29.456469Z","iopub.status.busy":"2024-04-04T10:43:29.455926Z","iopub.status.idle":"2024-04-04T10:43:29.463767Z","shell.execute_reply":"2024-04-04T10:43:29.462827Z","shell.execute_reply.started":"2024-04-04T10:43:29.456443Z"},"trusted":true},"outputs":[],"source":["def generate_csv(model,data,loader):\n","    model.eval()\n","    prediction=[]\n","    for batch in loader:\n","        x=batch[0].to(device)\n","        y=batch[1].to(device)\n","        o,w=model(x,y,tf=0)\n","        prediction.append(w)\n","    predicted_data_strings=[]\n","    for batch in prediction:\n","        for one_data in batch:\n","            one_data=one_data.to(torch.int)\n","            one_data_in_string=\"\"\n","            conv_int_word=[]\n","            for pos,value in enumerate(one_data):\n","                conv_int_word.append(data.sol_int2word[value.item()])\n","            predicted_data_strings.append(conv_int_word)\n","    return predicted_data_strings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:30.011770Z","iopub.status.busy":"2024-04-04T10:43:30.011405Z","iopub.status.idle":"2024-04-04T10:43:30.018153Z","shell.execute_reply":"2024-04-04T10:43:30.017063Z","shell.execute_reply.started":"2024-04-04T10:43:30.011742Z"},"trusted":true},"outputs":[],"source":["def extract_sol(data2str):\n","    complete_data=[]\n","    for each_data in data2str:\n","        s=\"\"\n","        flag=0\n","        for item in each_data[1:]:\n","            if(item==\"<eos>\" or item==\"<pad>\"):\n","                complete_data.append(s)\n","                flag=1\n","                break\n","            else:\n","                s+=str(item)\n","        if(flag==0):\n","            complete_data.append(s)\n","    return complete_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:31.238145Z","iopub.status.busy":"2024-04-04T10:43:31.237459Z","iopub.status.idle":"2024-04-04T10:43:31.244921Z","shell.execute_reply":"2024-04-04T10:43:31.243905Z","shell.execute_reply.started":"2024-04-04T10:43:31.238105Z"},"trusted":true},"outputs":[],"source":["def generate_sol(int2data,name,data_name):\n","    json_data=[]\n","    for k,s in zip(data_name.data,int2data):\n","        d={\n","            \"Problem\":k[0],\n","            \"answer\":k[2],\n","            \"predicted\":s,\n","            \"linear_formula\":k[1]\n","        }\n","        json_data.append(d)\n","    with open(str(name)+\".json\", 'w') as json_file:\n","        json.dump(json_data, json_file,indent=4)\n","    print(\"prediction json generated!!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:34.256918Z","iopub.status.busy":"2024-04-04T10:43:34.256152Z","iopub.status.idle":"2024-04-04T10:43:34.263247Z","shell.execute_reply":"2024-04-04T10:43:34.262114Z","shell.execute_reply.started":"2024-04-04T10:43:34.256884Z"},"trusted":true},"outputs":[],"source":["def convtostr(prediction,data):\n","    predicted_data_strings=[]\n","    for batch in prediction:\n","        for one_data in batch:\n","            one_data=one_data.to(torch.int)\n","            one_data_in_string=\"\"\n","            conv_int_word=[]\n","            for pos,value in enumerate(one_data):\n","                conv_int_word.append(data.sol_int2word[value.item()])\n","            predicted_data_strings.append(conv_int_word)\n","    return predicted_data_strings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:34.665982Z","iopub.status.busy":"2024-04-04T10:43:34.665553Z","iopub.status.idle":"2024-04-04T10:43:34.671434Z","shell.execute_reply":"2024-04-04T10:43:34.670286Z","shell.execute_reply.started":"2024-04-04T10:43:34.665949Z"},"trusted":true},"outputs":[],"source":["def get_me_final_file(op_test,data,file_name):\n","    prediction_in_str=convtostr(op_test,data)\n","    good=extract_sol(prediction_in_str)\n","    generate_sol(good,file_name,data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T10:43:47.357794Z","iopub.status.busy":"2024-04-04T10:43:47.357434Z","iopub.status.idle":"2024-04-04T10:43:53.285614Z","shell.execute_reply":"2024-04-04T10:43:53.284602Z","shell.execute_reply.started":"2024-04-04T10:43:47.357767Z"},"trusted":true},"outputs":[],"source":["op_test=[]\n","for i,one_data in enumerate(validation_loader1):\n","    beam=BeamSearch3(model=model,single_data=one_data,model_type=4, device=device,  max_target_len=300, beam_size=10)\n","    op_test.append(beam.search())\n","    print(f\"{i}th data completed\")\n","get_me_final_file(op_test,val_data,\"valid_beam_modelD\")\n","op_test=[]\n","for i,one_data in enumerate(test_loader):\n","    beam=BeamSearch3(model=model,single_data=one_data,model_type=4, device=device,  max_target_len=300, beam_size=10)\n","    op_test.append(beam.search())\n","    print(f\"{i}th data completed\")\n","get_me_final_file(op_test,test_data,\"test_beam_modelD\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4731290,"sourceId":8027701,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":26346.227723,"end_time":"2024-03-31T11:03:46.795594","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-03-31T03:44:40.567871","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"05af6d53952e4495ba346640fc5004a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6f7b8fcd3db44e88dc11d9b9d751469","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bf7bb629722429b8d85d1edeadd2733","value":435755784}},"31165ae69eb640e09039e4d80c5ae982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd03dac85c234518845bed99022a62fd","placeholder":"​","style":"IPY_MODEL_f58e83f604ce46f1a0370e5efee2a224","value":" 570/570 [00:00&lt;00:00, 38.2kB/s]"}},"3f42a55d1baa4523bed9949a75835221":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5307956c56bb45bba13f60b318a90266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"531589fd78b842dd9f646b3d6b089fd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e562f833aa543f79db35c1b1b708a19","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5307956c56bb45bba13f60b318a90266","value":570}},"60e8f00d260b45c4b09afe36cba7aefe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"751048dd41764fb88c9e9a96567dbefa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ded3ccd3f634c5dafb67b0d3d0d136a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e562f833aa543f79db35c1b1b708a19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84fa8c261e694f488072c87ab2952b96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bc4ad31b6d147b48ea943221533d5c4","IPY_MODEL_531589fd78b842dd9f646b3d6b089fd7","IPY_MODEL_31165ae69eb640e09039e4d80c5ae982"],"layout":"IPY_MODEL_60e8f00d260b45c4b09afe36cba7aefe"}},"8bc4ad31b6d147b48ea943221533d5c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ded3ccd3f634c5dafb67b0d3d0d136a","placeholder":"​","style":"IPY_MODEL_cc0c0d86c2044c1aabefc75dabef9e48","value":"config.json: 100%"}},"8bf7bb629722429b8d85d1edeadd2733":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3dba79df37e4c95ad631e3fd7678ea9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a537ec4a80964ae1bed02897bc9493db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f42a55d1baa4523bed9949a75835221","placeholder":"​","style":"IPY_MODEL_c3dfb5f2db0847c699c05a6a72d08600","value":"model.safetensors: 100%"}},"b47d84225ed74fef96185bb4a0a359f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd29c8898714448ca916fae71e32dbbc","placeholder":"​","style":"IPY_MODEL_751048dd41764fb88c9e9a96567dbefa","value":" 436M/436M [00:02&lt;00:00, 247MB/s]"}},"bd29c8898714448ca916fae71e32dbbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3dfb5f2db0847c699c05a6a72d08600":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c81f042f804945239f933b1982fdb011":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a537ec4a80964ae1bed02897bc9493db","IPY_MODEL_05af6d53952e4495ba346640fc5004a4","IPY_MODEL_b47d84225ed74fef96185bb4a0a359f0"],"layout":"IPY_MODEL_a3dba79df37e4c95ad631e3fd7678ea9"}},"cc0c0d86c2044c1aabefc75dabef9e48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd03dac85c234518845bed99022a62fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6f7b8fcd3db44e88dc11d9b9d751469":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f58e83f604ce46f1a0370e5efee2a224":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
